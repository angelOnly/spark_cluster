## 7. 集群启动流程

### Hadoop 集群启动

1. 启动 hdfs 集群：start-dfs.sh

2. 验证启动是否成功：jps 50070 端口

   访问 http://spark1:50070/ 浏览器，可以看到相关配置

````python
# jps 验证结果

spark1:
   5340 DataNode
   5219 NameNode
   5957 Jps
   5490 SecondaryNameNode
spark2:
   11262 DataNode
   11324 Jps

spark3:
	11340 Jps
	11278 DataNode
````

3. 执行 start-yarn.sh

````
spark1:
    3728 DataNode
    3916 SecondaryNameNode
    3625 NameNode
    4190 NodeManager
    4091 ResourceManager
    4534 Jps
spark3:
    3492 DataNode
    3731 Jps
    3603 NodeManager
spark2:
    3730 Jps
    3496 DataNode
    3603 NodeManager
````

### 启动 zookeeper 集群

分别在 3 台机器上执行

```
zkServer.sh start
```

检查 zookeeper 状态

```
zkServer.sh status
```

### 启动 Kafka 集群

````
nohup bin/kafka-server-start.sh config/server.properties &
````

### 启动 spark 集群

1. 在spark目录下的sbin目录
2. 执行./start-all.sh
3. 使用 jsp 和 <http://spark1:8080/> 端可以检查集群是否启动成功
4. 进入spark-shell查看是否正常
## Kafka 集群搭建

### scala 安装

将 scala-2.11.8.tgz 上传到 spark1 的 /usr/local 目录下

对 scala-2.11.8.tgz 进行解压

````
tar -zxvf scala-2.11.8.tgz
````

重命名 scala

```
mv scala-2.11.8 scala
```

配置 scala 环境

````
vi /etc/bashrc
source /etc/bashrc

export SCALA_HOME=/usr/local/scala
export PATH=$PATH:$SCALA_HOME/bin
````

查看 scala 是否安装成功

````
scala -version
````

按照上述步骤在 spark2 和 spark3 上都装好

使用 scp 将 scala 和 bashrc 文件拷贝到 spark2 和 spark3 即可

````
scp -r scala root@spark2:/usr/local/
scp -r /etc/bashrc root@spark2:/etc/
source /etc/bashrc
````

### kafka 安装

将 kafka_2.11-2.1.0.tgz 上传到 spark1 的 /usr/local 目录下，对 kafka_2.11-2.1.0.tgz 进行解压

````
tar -zxvf kafka_2.11-2.1.0.tgz
````

对 kafka 重命名

````
mv kafka_2.11-2.1.0 kafka
````

配置 kafka

````
vi /usr/local/kafka/config/server.properties

broker.id:依次增长的整数 0，1，2，3，4。 集群中 Broker 的唯一 id。
zookeeper connect=10.15.0.43:2181,10.15.0.44:2181,10.15.0.45:2181
````

**安装 slf4j**

将 slf4j-1.7.25.zip 上传到 /usr/local 目录下，对其进行解压

````
unzip slf4j-1.7.25.zip
````
>-bash: unzip: 未找到命令
>
>yum install unzip

将 /usr/local/slf4j-1.7.25/slf4j-nop-1.7.25.jar 复制到 kafka 的 libs 目录下

````
mv /usr/local/slf4j-1.7.25/slf4j-nop-1.7.25.jar /usr/local/kafka/libs/
````

按照上述步骤在 spark2 和 spark3 上配置，使用 scp 将 kafka 和 bashrc 拷贝到 spark2 和 spark3 上即可。

唯一的区别是 spark2 和 spark3 的 /kafka/config/server.properties 的 broker.id 分别设置为 1 和 2。

````
scp -r kafka root@spark2:/usr/local/
scp -r /etc/bashrc root@spark2:/etc/
source /etc/bashrc

vi /kafka/config/server.properties
````

### 启动 kafka 集群

在三台机器上分别执行命令，必须在 kafka 的安装目录下执行 /usr/local/kafka

````
nohup bin/kafka-server-start.sh config/server.properties &
````

> 解决 kafka Unrecognized VM option 'UseCompressedOops' 问题
>
> vi bin/kafka-run-class.sh
>  if [ -z "$KAFKA_JVM_PERFORMANCE_OPTS" ]; then 
>
> KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseCompressedOops - XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled - XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true"
>  fi 
>
> 去掉-XX:+UseCompressedOops即可 

使用 jps 检查启动是否成功

>JVM performance options
>
>if [ -z "$KAFKA_JVM_PERFORMANCE_OPTS" ]; then
> KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true"
>fi

使用基本命令检查 kafka 安装是否成功

````python
bin/kafka-topics.sh --zookeeper 10.15.0.43:2181,10.15.0.44:2181,10.15.0.45:2181 --topic Test --replication-factor 1 --partitions 1 --create

bin/kafka-console-producer.sh --broker-list 10.15.0.43:2181,10.15.0.44:2181,10.15.0.45:2181 --topic Test

### consumer zookeeper is not a recognized option
#bin/kafka-console-consumer.sh --zookeeper #10.15.0.43:2181,10.15.0.44:2181,10.15.0.45:2181 --topic Test --from-beginning
# --zookeeper是一个过时的方法，在最新的版本中，这种启动方式已经被删除了

bin/kafka-console-consumer.sh --bootstrap-server 10.15.0.43:2181,10.15.0.44:2181,10.15.0.45:2181 --topic Test --from-beginning
````

